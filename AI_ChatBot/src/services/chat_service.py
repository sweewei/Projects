from datetime import datetime
from typing import List, Dict, Optional, Any
from src.models.llm_model import llm_model
from src.services.vector_service import vector_service
from config.settings import settings
from src.utils.logger import setup_logger
from src.utils.exceptions import ChatSystemException

logger = setup_logger(__name__)

class ChatService:
    """èŠå¤©æœå‹™"""
    
    def __init__(self):
        self.chat_history: List[Dict[str, str]] = []
        self.last_interaction_time: Optional[datetime] = None
    
    def should_show_faq(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦æ‡‰è©²é¡¯ç¤º FAQ"""
        if not self.last_interaction_time:
            return False
        return datetime.now() - self.last_interaction_time > settings.FAQ_TIMEOUT
    
    def get_faq_questions(self) -> List[str]:
        """ç²å– FAQ å•é¡Œåˆ—è¡¨"""
        return settings.FAQ_QUESTIONS.copy()
    
    def reset_memory(self) -> None:
        """æ¸…é™¤èŠå¤©è¨˜æ†¶"""
        self.chat_history = []
        self.last_interaction_time = None
        logger.info("ğŸ§¹ èŠå¤©è¨˜æ†¶å·²æ¸…é™¤")
    
    def _manage_history_size(self) -> None:
        """ç®¡ç†èŠå¤©æ­·å²å¤§å°ï¼Œé˜²æ­¢è¨˜æ†¶é«”æ´©æ¼"""
        if len(self.chat_history) > settings.MAX_CHAT_HISTORY:
            # ä¿ç•™æœ€è¿‘çš„å°è©±ï¼Œä½†ä¿ç•™ç¬¬ä¸€æ¢ç³»çµ±æ¶ˆæ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            keep_count = settings.MAX_CHAT_HISTORY - 10
            self.chat_history = self.chat_history[-keep_count:]
            logger.info(f"ğŸ“ èŠå¤©æ­·å²å·²æˆªæ–·è‡³ {len(self.chat_history)} æ¢")
    
    def get_response(self, user_message: str) -> Dict[str, Any]:
        """ç²å–èŠå¤©å›æ‡‰"""
        try:
            # æ›´æ–°äº’å‹•æ™‚é–“
            self.last_interaction_time = datetime.now()
            
            # æª¢ç´¢ç›¸é—œæ–‡æª”
            retrieved_docs_with_score = vector_service.similarity_search_with_score(
                user_message, k=settings.RETRIEVAL_TOP_K
            )
            
            # è¨˜éŒ„æª¢ç´¢çµæœ
            self._log_retrieval_results(retrieved_docs_with_score)
            
            # å»ºæ§‹ä¸Šä¸‹æ–‡
            context = self._build_context(retrieved_docs_with_score)
            
            # æ·»åŠ ç”¨æˆ¶æ¶ˆæ¯åˆ°æ­·å²
            self.chat_history.append({"role": "user", "content": user_message})
            
            # å»ºæ§‹æç¤ºè©
            prompt = llm_model.build_prompt(self.chat_history, context)
            
            # ç”Ÿæˆå›æ‡‰
            generated_answer = llm_model.generate_response(prompt)
            
            # æ·»åŠ åŠ©æ‰‹å›æ‡‰åˆ°æ­·å²
            self.chat_history.append({"role": "assistant", "content": generated_answer})
            
            # ç®¡ç†æ­·å²å¤§å°
            self._manage_history_size()
            
            # æ•´ç†æª¢ç´¢æ–‡æª”æ‘˜è¦
            retrieved_docs_summary = [
                {
                    "source": doc.metadata.get("source", ""),
                    "score": float(score),
                    "preview": doc.page_content[:200]
                }
                for doc, score in retrieved_docs_with_score
            ]
            
            return {
                "reply": generated_answer,
                "retrieved_docs": retrieved_docs_summary,
                "last_interaction_time": self.last_interaction_time.isoformat(),
                "chat_history_length": len(self.chat_history)
            }
            
        except Exception as e:
            logger.error(f"âŒ ç²å–èŠå¤©å›æ‡‰å¤±æ•—: {e}")
            raise ChatSystemException(f"Failed to get chat response: {e}")
    
    def _build_context(self, retrieved_docs_with_score) -> str:
        """å»ºæ§‹æª¢ç´¢ä¸Šä¸‹æ–‡"""
        context_lines = []
        for doc, score in retrieved_docs_with_score:
            context_lines.append(f"[Score: {score:.4f}] {doc.page_content}")
        return "\n".join(context_lines)
    
    def _log_retrieval_results(self, retrieved_docs_with_score) -> None:
        """è¨˜éŒ„æª¢ç´¢çµæœ"""
        logger.info("=== æª¢ç´¢çµæœ (å«åˆ†æ•¸) ===")
        for doc, score in retrieved_docs_with_score:
            source = doc.metadata.get('source', 'Unknown')
            preview = doc.page_content[:100] + "..." if len(doc.page_content) > 100 else doc.page_content
            logger.info(f"[Score: {score:.4f}] {source}: {preview}")

# å…¨åŸŸèŠå¤©æœå‹™å¯¦ä¾‹
chat_service = ChatService()